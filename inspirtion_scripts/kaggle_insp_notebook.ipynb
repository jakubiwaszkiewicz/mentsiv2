{"cells":[{"cell_type":"markdown","metadata":{},"source":["# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>Cats & Dogs Classification with Pytorch from Scratch</b></p>\n","\n","![](https://github.com/TirendazAcademy/End-to-End-Deep-Learning-Projects/blob/main/image_classification_pytorch_comet/Images/images/dog-cat.png?raw=true)\n","\n","\n","ChatGPT is booming right now. ChatGPT was built using deep learning techniques. Deep learning is a subfield of machine learning that is concerned with the design and development of algorithms inspired by the structure and function of the brain, specifically artificial neural networks. These neural networks are composed of multiple layers and are able to learn features and representations of the data at multiple levels of abstraction. This allows deep learning models to achieve state-of-the-art performance on a wide range of tasks, such as image recognition, natural language processing, and speech recognition.\n","\n","This notebook walks you through how to build a CNN model for image classification and predict data using this model with PyTorch.\n","\n","### What is Image Classification?\n","\n","![](https://github.com/TirendazAcademy/End-to-End-Deep-Learning-Projects/blob/main/image_classification_pytorch_comet/Images/images/cnn.png?raw=true)\n","\n","Image classification is the task of assigning a label or class to an input image based on its content. This is typically done using machine learning algorithms that have been trained on a dataset of labeled images. Let's take a look at what we'll learn in this tutorial.\n","\n","<b>*Table of contents:*</b>\n","<ul>\n","<li><a href=\"#Loading\">Loading the dataset</a></li>  \n","<li><a href=\"#Understanding\">Understanding the dataset</a></li>         \n","<li><a href=\"#Transforming-data\">Transforming data</a></li>\n","<li><a href=\"#Loading-image-data\">Loading image data</a></li>\n","<li><a href=\"#Model-building\">Model building</a></li>\n","<li><a href=\"#Prediction\">Make a prediction</a></li>\n","</ul>"]},{"cell_type":"markdown","metadata":{},"source":["Let's start by looking at the version of the torch."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:09:10.303381Z","iopub.status.busy":"2023-01-25T18:09:10.302429Z","iopub.status.idle":"2023-01-25T18:09:12.465126Z","shell.execute_reply":"2023-01-25T18:09:12.463511Z","shell.execute_reply.started":"2023-01-25T18:09:10.303259Z"},"id":"opMaq45sNwic","outputId":"3f1c70ff-d143-4a2d-90d3-57e2a2a2810b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.3.0\n"]}],"source":["import torch\n","from torch import nn\n","\n","# Note: this notebook requires torch >= 1.10.0\n","print(torch.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["## Why should you use Pytorch for deep learning?\n","\n","PyTorch is a popular deep learning framework because it is easy to use and offers a lot of flexibility. \n","\n","![](https://github.com/TirendazAcademy/End-to-End-Deep-Learning-Projects/blob/main/image_classification_pytorch_comet/Images/images/pytroch_features.png?raw=true)\n","\n","[Image reference](https://pytorch.org/features/)\n","\n","Here are some of the main reasons PyTorch is used for deep learning projects:\n","\n","- Dynamic computation graph: PyTorch allows for building dynamic computation graphs, which means that the user can change the graph on the fly, during runtime.\n","- Easy to use API: PyTorch has a simple, intuitive API, which makes it easy for developers to get started with building deep learning models.\n","- Large community and support: PyTorch has a large and active community of developers, which means that there are many resources available, such as tutorials, pre-trained models, and third-party libraries.\n","- Interoperability with other frameworks: PyTorch can seamlessly integrate with other frameworks such as TensorFlow, enabling the user to take advantage of the best of both worlds.\n","- Support for CUDA: PyTorch supports CUDA, which is a parallel computing platform and API for using GPUs to accelerate computation. This can significantly speed up the training process for deep learning models.\n","\n","Overall, PyTorch is a great choice for deep learning projects because of its flexibility, ease of use, and strong community support. We talked about Pytorch. Let's go ahead and check if Cuda exists."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:11:48.68144Z","iopub.status.busy":"2023-01-25T18:11:48.680918Z","iopub.status.idle":"2023-01-25T18:11:48.837383Z","shell.execute_reply":"2023-01-25T18:11:48.835613Z","shell.execute_reply.started":"2023-01-25T18:11:48.681406Z"},"id":"-FomRxCGNzMc","outputId":"a254cd39-7ab5-475a-8861-6b9390499dd0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Setup device-agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"SdTJCw2kEYOW"},"source":["<a id=\"Loading\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>1. Loading the Dataset</b></p>\n","\n","The dataset we will use for this tutorial is the cat and dog dataset, which contains images of cats and dogs. Let's take a look at the files in the dataset folder. To do this, let me create a function."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:12:06.294444Z","iopub.status.busy":"2023-01-25T18:12:06.294079Z","iopub.status.idle":"2023-01-25T18:12:15.836771Z","shell.execute_reply":"2023-01-25T18:12:15.835337Z","shell.execute_reply.started":"2023-01-25T18:12:06.294413Z"},"id":"x-i9_Ss89RiS","trusted":true},"outputs":[],"source":["import os\n","def walk_through_dir(dir_path):\n","  for dirpath, dirnames, filenames in os.walk(dir_path):\n","    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n","    \n","image_path = \"d/ogs_vs_cats\"\n","walk_through_dir(image_path)"]},{"cell_type":"markdown","metadata":{},"source":["Nice! We saw the files in the dataset folder. Now let's create train and testing paths:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:13:00.373995Z","iopub.status.busy":"2023-01-25T18:13:00.373607Z","iopub.status.idle":"2023-01-25T18:13:00.381587Z","shell.execute_reply":"2023-01-25T18:13:00.380671Z","shell.execute_reply.started":"2023-01-25T18:13:00.373964Z"},"id":"tCxPmTcQ-BL4","outputId":"a8ca6a26-a01a-4392-8497-44530470080e","trusted":true},"outputs":[{"data":{"text/plain":["('dogs_vs_cats/train', 'dogs_vs_cats/test')"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_dir = \"dogs_vs_cats/train\"\n","test_dir = \"dogs_vs_cats/test\"\n","train_dir, test_dir"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"Understanding\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>2. Understanding the Dataset</b></p>\n","\n","It is important to understand the dataset for deep learning analysis because the dataset is the foundation of any machine learning or deep learning model. A deep learning model can only be as good as the data it is trained on, and a poor understanding of the dataset can lead to poor model performance or even bias. Now let's take a look at an image in the dataset."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:17:39.884221Z","iopub.status.busy":"2023-01-25T18:17:39.883852Z","iopub.status.idle":"2023-01-25T18:17:39.966048Z","shell.execute_reply":"2023-01-25T18:17:39.965124Z","shell.execute_reply.started":"2023-01-25T18:17:39.88419Z"},"id":"Dh5tUEeY-sWk","outputId":"dd5445b2-7fb3-4d66-cef5-8476ad7af591","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[]\n"]},{"ename":"IndexError","evalue":"Cannot choose from an empty sequence","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m exit()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Get random image path\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m random_image_path \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(image_path_list)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m image_class \u001b[38;5;241m=\u001b[39m Path(random_image_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mstem\n","File \u001b[1;32mc:\\Users\\itakw\\miniconda3\\Lib\\random.py:347\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n","\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import random\n","from PIL import Image\n","import glob\n","from pathlib import Path\n","\n","# Set seed\n","random.seed(42) \n","\n","# 1. Get all image paths (* means \"any combination\")\n","image_path_list= glob.glob(f\"{image_path}/*/*/*.jpg\")\n","\n","print(image_path_list)\n","\n","# 2. Get random image path\n","random_image_path = random.choice(image_path_list)\n","\n","# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n","image_class = Path(random_image_path).parent.stem\n","\n","# 4. Open image\n","img = Image.open(random_image_path)\n","\n","# 5. Print metadata\n","print(f\"Random image path: {random_image_path}\")\n","print(f\"Image class: {image_class}\")\n","print(f\"Image height: {img.height}\") \n","print(f\"Image width: {img.width}\")\n","img"]},{"cell_type":"markdown","metadata":{},"source":["Beautiful cute cat isn't it? I love cats. So can't we use matplotlib for data visualization? Definitely yes. Let me show you."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:17:53.882712Z","iopub.status.busy":"2023-01-25T20:17:53.882329Z","iopub.status.idle":"2023-01-25T20:17:54.584955Z","shell.execute_reply":"2023-01-25T20:17:54.583338Z","shell.execute_reply.started":"2023-01-25T20:17:53.882678Z"},"id":"9yiV3Z_RDkAI","outputId":"6119a3ff-5ba9-42ef-b7b1-305d80eb8e95","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'img' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_theme()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Turn the image into an array\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m img_as_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(img)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plot the image with matplotlib\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n","\u001b[1;31mNameError\u001b[0m: name 'img' is not defined"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_theme()\n","\n","# Turn the image into an array\n","img_as_array = np.asarray(img)\n","\n","# Plot the image with matplotlib\n","plt.figure(figsize=(8, 6))\n","plt.imshow(img_as_array)\n","plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n","plt.axis(False);"]},{"cell_type":"markdown","metadata":{"id":"tXCiyY6vEUMs"},"source":["<a id=\"Transforming-data\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>3. Transforming Data</b></p>\n","\n","Transforming data, also known as preprocessing, is an important step in deep learning analysis because it can help to improve the performance of the model and reduce the risk of bias. Let's play with the images a bit with the `transform` method."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:23:20.258102Z","iopub.status.busy":"2023-01-25T18:23:20.257737Z","iopub.status.idle":"2023-01-25T18:23:20.511208Z","shell.execute_reply":"2023-01-25T18:23:20.509987Z","shell.execute_reply.started":"2023-01-25T18:23:20.258064Z"},"id":"9Bwx1c5VEJeS","trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","\n","IMAGE_WIDTH=128\n","IMAGE_HEIGHT=128\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","\n","# Write transform for image\n","data_transform = transforms.Compose([\n","    # Resize the images to IMAGE_SIZE xIMAGE_SIZE \n","    transforms.Resize(size=IMAGE_SIZE),\n","    # Flip the images randomly on the horizontal\n","    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n","    # Turn the image into a torch.Tensor\n","    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n","])"]},{"cell_type":"markdown","metadata":{},"source":["To understand how to transform the images, let's use data visualization. To do this, I'm going to craete a function named plot_transformed_images."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:24:46.546546Z","iopub.status.busy":"2023-01-25T18:24:46.546174Z","iopub.status.idle":"2023-01-25T18:24:47.251338Z","shell.execute_reply":"2023-01-25T18:24:47.250438Z","shell.execute_reply.started":"2023-01-25T18:24:46.546515Z"},"id":"_LY7nHI0FMeE","outputId":"943ef950-e112-4c8b-be58-6c3647f6d737","trusted":true},"outputs":[],"source":["def plot_transformed_images(image_paths, transform, n=3, seed=42):\n","    random.seed(seed)\n","    random_image_paths = random.sample(image_paths, k=n)\n","    for image_path in random_image_paths:\n","        with Image.open(image_path) as f:\n","            fig, ax = plt.subplots(1, 2)\n","            ax[0].imshow(f) \n","            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n","            ax[0].axis(\"off\")\n","\n","            # Transform and plot image\n","            # Note: permute() will change shape of image to suit matplotlib \n","            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n","            transformed_image = transform(f).permute(1, 2, 0) \n","            ax[1].imshow(transformed_image) \n","            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n","            ax[1].axis(\"off\")\n","            fig.suptitle(f\"Class: {Path(random_image_path).parent.stem}\", fontsize=16)\n","\n","plot_transformed_images(image_path_list, transform=data_transform, n=3)"]},{"cell_type":"markdown","metadata":{},"source":["Nice! we saw how to transform images. Let's go ahead and load our dataset."]},{"cell_type":"markdown","metadata":{"id":"9LrpI_fKGX1H"},"source":["<a id=\"Loading-image-data\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>4. Loading Image Data</b></p>\n","So far, we created a data transformation function. We are ready to load our dataset using this function. The easiest way to load data is to use the `ImageFolder` function in PyTorch. Let's load the dataset with this function."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:28:36.255425Z","iopub.status.busy":"2023-01-25T18:28:36.255032Z","iopub.status.idle":"2023-01-25T18:28:37.584602Z","shell.execute_reply":"2023-01-25T18:28:37.583503Z","shell.execute_reply.started":"2023-01-25T18:28:36.255391Z"},"id":"kYSJqf81GXb0","outputId":"ae2bcaba-26b8-4532-b2f3-4a546f492296","trusted":true},"outputs":[],"source":["from torchvision import datasets\n","\n","# Creating training set\n","train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n","                                  transform=data_transform, # transforms to perform on data (images)\n","                                  target_transform=None) # transforms to perform on labels (if necessary)\n","#Creating test set\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"]},{"cell_type":"markdown","metadata":{},"source":["Now let's discover the dataset using the attributes as shown below."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:31:34.131281Z","iopub.status.busy":"2023-01-25T18:31:34.130925Z","iopub.status.idle":"2023-01-25T18:31:34.138127Z","shell.execute_reply":"2023-01-25T18:31:34.136994Z","shell.execute_reply.started":"2023-01-25T18:31:34.131251Z"},"id":"TvLTj_T1G535","outputId":"0dc33d5b-dbca-4008-e9d4-83d029d5a607","trusted":true},"outputs":[],"source":["# Get class names as a list\n","class_names = train_data.classes\n","print(\"Class names: \",class_names)\n","\n","# Can also get class names as a dict\n","class_dict = train_data.class_to_idx\n","print(\"Class names as a dict: \",class_dict)\n","\n","# Check the lengths\n","print(\"The lengths of the training and test sets: \", len(train_data), len(test_data))"]},{"cell_type":"markdown","metadata":{},"source":["Awesome. We learned some information about the datasets. Let's get an image and have a look at its features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:31:40.515413Z","iopub.status.busy":"2023-01-25T18:31:40.515055Z","iopub.status.idle":"2023-01-25T18:31:40.543703Z","shell.execute_reply":"2023-01-25T18:31:40.542614Z","shell.execute_reply.started":"2023-01-25T18:31:40.515382Z"},"id":"FRHcIRLBH5-C","outputId":"dd613725-38e6-408e-e783-a70afc7e7fe0","trusted":true},"outputs":[],"source":["img, label = train_data[0][0], train_data[0][1]\n","print(f\"Image tensor:\\n{img}\")\n","print(f\"Image shape: {img.shape}\")\n","print(f\"Image datatype: {img.dtype}\")\n","print(f\"Image label: {label}\")\n","print(f\"Label datatype: {type(label)}\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize this image with matplotlib."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:33:29.123208Z","iopub.status.busy":"2023-01-25T18:33:29.122849Z","iopub.status.idle":"2023-01-25T18:33:29.384235Z","shell.execute_reply":"2023-01-25T18:33:29.383403Z","shell.execute_reply.started":"2023-01-25T18:33:29.123176Z"},"id":"VAYrBKA5IDh5","outputId":"2aca7fb1-6956-4e72-e68b-c0ba51220a21","trusted":true},"outputs":[],"source":["# Rearrange the order of dimensions\n","img_permute = img.permute(1, 2, 0)\n","\n","# Print out different shapes (before and after permute)\n","print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n","print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n","\n","# Plot the image\n","plt.figure(figsize=(10, 7))\n","plt.imshow(img.permute(1, 2, 0))\n","plt.axis(\"off\")\n","plt.title(class_names[label], fontsize=14);"]},{"cell_type":"markdown","metadata":{"id":"NRm0ua4DI9cc"},"source":["## Turn loaded images into DataLoader's\n","\n","So far, we loaded images. Note that a `DataLoader` in PyTorch is a utility used to load data from a dataset object in parallel. It allows the user to load data in batches, which can be useful for training deep learning models, as it enables the model to process multiple samples at once, which can speed up the training process. Additionally, it also allows the user to shuffle the data, which can help to prevent overfitting.\n","\n","The DataLoader takes a dataset object and several other optional parameters, such as the batch size, the number of worker threads to use for loading the data, and a boolean flag for whether or not to shuffle the data. The DataLoader will then return an iterator that can be used to iterate over the data in batches. \n","\n","Excellent! we talked a little bit about DataLoader. Show time:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:42:51.027703Z","iopub.status.busy":"2023-01-25T18:42:51.027331Z","iopub.status.idle":"2023-01-25T18:42:51.035919Z","shell.execute_reply":"2023-01-25T18:42:51.034873Z","shell.execute_reply.started":"2023-01-25T18:42:51.027669Z"},"id":"X6cgGISJI4PR","outputId":"02c649f4-c459-44a3-c7fc-aeed0372f512","trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# How many subprocesses will be used for data loading (higher = more)\n","NUM_WORKERS = os.cpu_count()\n","\n","# Turn train and test Datasets into DataLoaders\n","train_dataloader = DataLoader(dataset=train_data, \n","                              batch_size=1, # how many samples per batch?\n","                              num_workers=NUM_WORKERS,\n","                              shuffle=True) # shuffle the data?\n","\n","test_dataloader = DataLoader(dataset=test_data, \n","                             batch_size=1, \n","                             num_workers=NUM_WORKERS, \n","                             shuffle=False) # don't usually need to shuffle testing data\n","\n","train_dataloader, test_dataloader"]},{"cell_type":"markdown","metadata":{},"source":["Nice. We turn our dataset into a `DataLoader` object. Now let's get a batch image and check the shape of this batch. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T18:44:16.049559Z","iopub.status.busy":"2023-01-25T18:44:16.049084Z","iopub.status.idle":"2023-01-25T18:44:16.182653Z","shell.execute_reply":"2023-01-25T18:44:16.181502Z","shell.execute_reply.started":"2023-01-25T18:44:16.049521Z"},"id":"zSaEmqi_JMp5","outputId":"ee5667c0-5436-4268-b40d-6d71770a9f07","trusted":true},"outputs":[],"source":["img, label = next(iter(train_dataloader))\n","\n","# Note that batch size will now be 1.  \n","print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n","print(f\"Label shape: {label.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"_02nLX-NKrnj"},"source":["<a id=\"Model-building\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>5. Model Building with Data Augmentation</b></p>\n","\n","Have you heard of what data augmentation is? Data augmentation is a technique used to artificially increase the size of a dataset by applying random modifications to the existing data. This can help to improve the performance of deep learning models by providing the model with more diverse training examples. Data augmentation can be useful when the available dataset is small or when the model is prone to overfitting.\n","\n","Some common data augmentation techniques include:\n","\n","- Random flipping or rotation of images\n","- Random cropping of images\n","- Random changes to brightness, contrast or color\n","- Adding noise to images\n","- Scaling or translation of images\n","\n","By using data augmentation techniques, the model can learn to generalize better and become more robust to small variations in the data. This can help to prevent overfitting and improve the model's performance on unseen data. It is important to note that data augmentation should be performed before data preprocessing. Keep in mind data augmentation should be applied only to the training set, not the validation or test set."]},{"cell_type":"markdown","metadata":{"id":"fQtclsnSNEte"},"source":["## 5.1 Creating transforms and loading data\n","\n","TrivialAugmentWide is a data augmentation technique in PyTorch that applies random resizing and cropping to an image. The technique is intended to be used as a \"wide\" data augmentation technique, meaning that it makes a large number of random transformations to the image in order to increase the diversity of the training data. This can help to improve the robustness and generalization of a machine learning model. [This example](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) illustrates the various transforms available in the torchvision.transforms module."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:25.254914Z","iopub.status.busy":"2023-01-25T19:18:25.254441Z","iopub.status.idle":"2023-01-25T19:18:25.260685Z","shell.execute_reply":"2023-01-25T19:18:25.259677Z","shell.execute_reply.started":"2023-01-25T19:18:25.254873Z"},"id":"RY-UzszvKrKW","trusted":true},"outputs":[],"source":["# Set image size.\n","IMAGE_WIDTH = 224\n","IMAGE_HEIGHT = 224\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","\n","# Create training transform with TrivialAugment\n","train_transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),\n","    transforms.TrivialAugmentWide(),\n","    transforms.ToTensor()])\n","\n","# Create testing transform (no data augmentation)\n","test_transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),\n","    transforms.ToTensor()])"]},{"cell_type":"markdown","metadata":{},"source":["Now let's load our dataset with data augmentation again."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:29.205928Z","iopub.status.busy":"2023-01-25T19:18:29.204794Z","iopub.status.idle":"2023-01-25T19:18:30.737604Z","shell.execute_reply":"2023-01-25T19:18:30.736513Z","shell.execute_reply.started":"2023-01-25T19:18:29.205889Z"},"id":"mIdSIQORLd14","outputId":"776dbcf3-57cc-4419-b95e-5a767a826ec2","trusted":true},"outputs":[],"source":["# Turn image folders into Datasets\n","train_data_augmented = datasets.ImageFolder(train_dir, transform=train_transform)\n","test_data_augmented = datasets.ImageFolder(test_dir, transform=test_transform)\n","\n","train_data_augmented, test_data_augmented"]},{"cell_type":"markdown","metadata":{},"source":["Now let's turn Datasets into DataLoader's."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:37.338425Z","iopub.status.busy":"2023-01-25T19:18:37.338043Z","iopub.status.idle":"2023-01-25T19:18:37.346352Z","shell.execute_reply":"2023-01-25T19:18:37.345164Z","shell.execute_reply.started":"2023-01-25T19:18:37.338392Z"},"id":"O_rQ4PllMe04","outputId":"2a3ffefc-d582-4f28-b33d-2a0c2958db8d","trusted":true},"outputs":[],"source":["# Set some parameters.\n","BATCH_SIZE = 32\n","torch.manual_seed(42)\n","\n","train_dataloader_augmented = DataLoader(train_data_augmented, \n","                                        batch_size=BATCH_SIZE, \n","                                        shuffle=True,\n","                                        num_workers=NUM_WORKERS)\n","\n","test_dataloader_augmented = DataLoader(test_data_augmented, \n","                                       batch_size=BATCH_SIZE, \n","                                       shuffle=False, \n","                                       num_workers=NUM_WORKERS)\n","\n","train_dataloader_augmented, test_dataloader_augmented"]},{"cell_type":"markdown","metadata":{},"source":["Nice! We created the `DataLoader` objects. Let's go ahead and build an image classification architecture."]},{"cell_type":"markdown","metadata":{"id":"cVDWp25FNRM_"},"source":["## 5.2 Creating CNN Image Classifier"]},{"cell_type":"markdown","metadata":{},"source":["A convolutional neural network (CNN) is a type of deep learning neural network that is primarily used for image and video recognition tasks. CNNs are designed to process data that has a grid-like topology, such as an image, which is composed of pixels arranged in a 2D grid. The architecture of a CNN consists of several layers, including convolutional layers, pooling layers, and fully connected layers.\n","\n","The convolutional layers are responsible for detecting features in the input image by applying a set of learnable filters to the image. These filters are convolved with the input image to produce a set of feature maps, which are then passed through pooling layers to reduce the spatial dimensions of the feature maps and retain only the most salient features. The fully connected layers then process the pooled feature maps to produce the final output, such as a classification label.\n","\n","CNNs have been used to achieve state-of-the-art results on a wide range of computer vision tasks such as image classification, object detection, and semantic segmentation. Now let's go ahead and build a CNN model with nn.Module in Pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:47.73452Z","iopub.status.busy":"2023-01-25T19:18:47.734146Z","iopub.status.idle":"2023-01-25T19:18:47.776234Z","shell.execute_reply":"2023-01-25T19:18:47.775192Z","shell.execute_reply.started":"2023-01-25T19:18:47.734487Z"},"id":"j99yPcDCtnPG","outputId":"45bba9bf-3063-4ab7-c820-8b95a351b6e8","trusted":true},"outputs":[],"source":["# # Creating a CNN-based image classifier.\n","class ImageClassifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv_layer_1 = nn.Sequential(\n","          nn.Conv2d(3, 64, 3, padding=1),\n","          nn.ReLU(),\n","          nn.BatchNorm2d(64),\n","          nn.MaxPool2d(2))\n","        self.conv_layer_2 = nn.Sequential(\n","          nn.Conv2d(64, 512, 3, padding=1),\n","          nn.ReLU(),\n","          nn.BatchNorm2d(512),\n","          nn.MaxPool2d(2))\n","        self.conv_layer_3 = nn.Sequential(\n","          nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","          nn.ReLU(),\n","          nn.BatchNorm2d(512),\n","          nn.MaxPool2d(2)) \n","        self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          nn.Linear(in_features=512*3*3, out_features=2))\n","    def forward(self, x: torch.Tensor):\n","        x = self.conv_layer_1(x)\n","        x = self.conv_layer_2(x)\n","        x = self.conv_layer_3(x)\n","        x = self.conv_layer_3(x)\n","        x = self.conv_layer_3(x)\n","        x = self.conv_layer_3(x)\n","        x = self.classifier(x)\n","        return x\n","# Instantiate an object.\n","model = ImageClassifier().to(device)"]},{"cell_type":"markdown","metadata":{"id":"C4J-DUNXQbSB"},"source":["## 5.3 Try a forward pass on a single image (to test the model)\n","\n","Ok, we created a CNN-based model. But does this model work? To understand this, let's pass a image through the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:52.164904Z","iopub.status.busy":"2023-01-25T19:18:52.164522Z","iopub.status.idle":"2023-01-25T19:18:52.842147Z","shell.execute_reply":"2023-01-25T19:18:52.840625Z","shell.execute_reply.started":"2023-01-25T19:18:52.164873Z"},"id":"W3QEE5CBQa7j","outputId":"2c2fa771-8ca4-4ca9-b643-27318a632e84","trusted":true},"outputs":[],"source":["# 1. Get a batch of images and labels from the DataLoader\n","img_batch, label_batch = next(iter(train_dataloader_augmented))\n","\n","# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n","img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n","print(f\"Single image shape: {img_single.shape}\\n\")\n","\n","# 3. Perform a forward pass on a single image\n","model.eval()\n","with torch.inference_mode():\n","    pred = model(img_single.to(device))\n","    \n","# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n","print(f\"Output logits:\\n{pred}\\n\")\n","print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n","print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n","print(f\"Actual label:\\n{label_single}\")"]},{"cell_type":"markdown","metadata":{},"source":["Nice! Our model is working for an image. Let's go ahead and try to understand this model."]},{"cell_type":"markdown","metadata":{"id":"2U_Kti1FRZUE"},"source":["## 5.4 Understanding the model\n","\n","It is important to understand the model architecture. Fortunately, there is the `torchinfo` package to see the architecture of the model. Let me show you."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:18:58.378787Z","iopub.status.busy":"2023-01-25T19:18:58.378344Z","iopub.status.idle":"2023-01-25T19:18:58.398592Z","shell.execute_reply":"2023-01-25T19:18:58.397488Z","shell.execute_reply.started":"2023-01-25T19:18:58.378743Z"},"id":"iDdzcRfVRP2a","outputId":"078bff53-f872-4aff-bdbf-de6487d7fd4a","trusted":true},"outputs":[],"source":["from torchinfo import summary\n","# do a test pass through of an example input size \n","summary(model, input_size=[1, 3, IMAGE_WIDTH ,IMAGE_HEIGHT]) "]},{"cell_type":"markdown","metadata":{"id":"K3n4unqvRxVW"},"source":["## 5.5 Create train & test loop functions"]},{"cell_type":"markdown","metadata":{},"source":["Note that the model is built on the training data and tested on the validation set. Now let's create two function to train and test the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:22:26.399406Z","iopub.status.busy":"2023-01-25T19:22:26.399017Z","iopub.status.idle":"2023-01-25T19:22:26.4105Z","shell.execute_reply":"2023-01-25T19:22:26.409401Z","shell.execute_reply.started":"2023-01-25T19:22:26.399371Z"},"id":"K0cOVqstRwCZ","trusted":true},"outputs":[],"source":["def train_step(model: torch.nn.Module, \n","               dataloader: torch.utils.data.DataLoader, \n","               loss_fn: torch.nn.Module, \n","               optimizer: torch.optim.Optimizer):\n","    # Put model in train mode\n","    model.train()\n","    \n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0\n","    \n","    # Loop through data loader data batches\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Send data to target device\n","        X, y = X.to(device), y.to(device)\n","        \n","        # 1. Forward pass\n","        y_pred = model(X)\n","\n","        # 2. Calculate  and accumulate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item() \n","\n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","\n","        # 4. Loss backward\n","        loss.backward()\n","\n","        # 5. Optimizer step\n","        optimizer.step()\n","\n","        # Calculate and accumulate accuracy metric across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch \n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:22:29.234194Z","iopub.status.busy":"2023-01-25T19:22:29.233822Z","iopub.status.idle":"2023-01-25T19:22:29.242405Z","shell.execute_reply":"2023-01-25T19:22:29.241072Z","shell.execute_reply.started":"2023-01-25T19:22:29.234161Z"},"id":"lAxEiSgWS3rv","trusted":true},"outputs":[],"source":["def test_step(model: torch.nn.Module, \n","              dataloader: torch.utils.data.DataLoader, \n","              loss_fn: torch.nn.Module):\n","    # Put model in eval mode\n","    model.eval() \n","    \n","    # Setup test loss and test accuracy values\n","    test_loss, test_acc = 0, 0\n","    \n","    # Turn on inference context manager\n","    with torch.inference_mode():\n","        # Loop through DataLoader batches\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send data to target device\n","            X, y = X.to(device), y.to(device)\n","    \n","            # 1. Forward pass\n","            test_pred_logits = model(X)\n","\n","            # 2. Calculate and accumulate loss\n","            loss = loss_fn(test_pred_logits, y)\n","            test_loss += loss.item()\n","            \n","            # Calculate and accumulate accuracy\n","            test_pred_labels = test_pred_logits.argmax(dim=1)\n","            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","            \n","    # Adjust metrics to get average loss and accuracy per batch \n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc"]},{"cell_type":"markdown","metadata":{"id":"UsAKvGwpTAS7"},"source":["Now let's create a function named train to combine the train_step and test_step functions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:22:36.907367Z","iopub.status.busy":"2023-01-25T19:22:36.906967Z","iopub.status.idle":"2023-01-25T19:22:36.920629Z","shell.execute_reply":"2023-01-25T19:22:36.919446Z","shell.execute_reply.started":"2023-01-25T19:22:36.90733Z"},"id":"uhTD1INIS_UA","trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","\n","# 1. Take in various parameters required for training and test steps\n","def train(model: torch.nn.Module, \n","          train_dataloader: torch.utils.data.DataLoader, \n","          test_dataloader: torch.utils.data.DataLoader, \n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n","          epochs: int = 5):\n","    \n","    # 2. Create empty results dictionary\n","    results = {\"train_loss\": [],\n","        \"train_acc\": [],\n","        \"test_loss\": [],\n","        \"test_acc\": []\n","    }\n","    \n","    # 3. Loop through training and testing steps for a number of epochs\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                           dataloader=train_dataloader,\n","                                           loss_fn=loss_fn,\n","                                           optimizer=optimizer)\n","        test_loss, test_acc = test_step(model=model,\n","            dataloader=test_dataloader,\n","            loss_fn=loss_fn)\n","        \n","        # 4. Print out what's happening\n","        print(\n","            f\"Epoch: {epoch+1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","            f\"test_loss: {test_loss:.4f} | \"\n","            f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        # 5. Update results dictionary\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","\n","    # 6. Return the filled results at the end of the epochs\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"2NXEloaeTUtP"},"source":["## 5.6 Train and Evaluate Model"]},{"cell_type":"markdown","metadata":{},"source":["So far, we created training and test steps. We are ready to train the model using these steps. Show time:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T19:27:08.054338Z","iopub.status.busy":"2023-01-25T19:27:08.053957Z","iopub.status.idle":"2023-01-25T20:16:03.472841Z","shell.execute_reply":"2023-01-25T20:16:03.471563Z","shell.execute_reply.started":"2023-01-25T19:27:08.054305Z"},"id":"n8K6e7DeTShp","outputId":"af4f43fc-5a21-4214-e655-91b99396e153","trusted":true},"outputs":[],"source":["# Set random seeds\n","torch.manual_seed(42) \n","torch.cuda.manual_seed(42)\n","\n","# Set number of epochs\n","NUM_EPOCHS = 25\n","\n","# Setup loss function and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n","\n","# Start the timer\n","from timeit import default_timer as timer \n","start_time = timer()\n","\n","# Train model_0 \n","model_results = train(model=model,\n","                      train_dataloader=train_dataloader_augmented,\n","                      test_dataloader=test_dataloader_augmented,\n","                      optimizer=optimizer,\n","                      loss_fn=loss_fn,\n","                      epochs=NUM_EPOCHS)\n","\n","# End the timer and print out how long it took\n","end_time = timer()\n","print(f\"Total training time: {end_time-start_time:.3f} seconds\")"]},{"cell_type":"markdown","metadata":{},"source":["Beautiful. It's done. Now we had a model for image classification. "]},{"cell_type":"markdown","metadata":{"id":"PaUumQA9jZhh"},"source":["## 5.7 Plot the loss curves of Model\n","\n","To understand the performance of model, let's visualize the loss and accuracy values."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:16:57.142622Z","iopub.status.busy":"2023-01-25T20:16:57.142225Z","iopub.status.idle":"2023-01-25T20:16:57.151211Z","shell.execute_reply":"2023-01-25T20:16:57.149796Z","shell.execute_reply.started":"2023-01-25T20:16:57.142583Z"},"id":"WevAWGI_kLf4","trusted":true},"outputs":[],"source":["def plot_loss_curves(results):\n","  \n","    results = dict(list(model_results.items()))\n","\n","    # Get the loss values of the results dictionary (training and test)\n","    loss = results['train_loss']\n","    test_loss = results['test_loss']\n","\n","    # Get the accuracy values of the results dictionary (training and test)\n","    accuracy = results['train_acc']\n","    test_accuracy = results['test_acc']\n","\n","    # Figure out how many epochs there were\n","    epochs = range(len(results['train_loss']))\n","\n","    # Setup a plot \n","    plt.figure(figsize=(15, 7))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, loss, label='train_loss')\n","    plt.plot(epochs, test_loss, label='test_loss')\n","    plt.title('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, accuracy, label='train_accuracy')\n","    plt.plot(epochs, test_accuracy, label='test_accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend();"]},{"cell_type":"markdown","metadata":{},"source":["It is time to visualize for the loss and accuracy values using this function."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:18:05.891622Z","iopub.status.busy":"2023-01-25T20:18:05.891221Z","iopub.status.idle":"2023-01-25T20:18:06.412054Z","shell.execute_reply":"2023-01-25T20:18:06.411059Z","shell.execute_reply.started":"2023-01-25T20:18:05.891589Z"},"id":"3uS-wF6wmH0B","outputId":"aca58bb7-7f47-4965-ca12-b14d216ba74d","trusted":true},"outputs":[],"source":["plot_loss_curves(model_results)"]},{"cell_type":"markdown","metadata":{},"source":["Awesome. The performance of our model is not bad on both the training and test datasets. Let's go ahead and take a look at how to make a prediction."]},{"cell_type":"markdown","metadata":{"id":"i4S-9BpBnhM6"},"source":["<a id=\"Prediction\"></a>\n","# <p style=\"background-color:coral;font-family:newtimeroman;font-size:150%;color:white;text-align:center;border-radius:20px 20px;\"><b>6. Make a Prediction</b></p>\n","\n","Now we had a good model for image classification. But, how does this model predict new data? To understand this let me make a prediction on a custom image. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:18:46.237638Z","iopub.status.busy":"2023-01-25T20:18:46.237238Z","iopub.status.idle":"2023-01-25T20:18:46.257519Z","shell.execute_reply":"2023-01-25T20:18:46.256585Z","shell.execute_reply.started":"2023-01-25T20:18:46.237603Z"},"id":"c2Cke99ToEZr","outputId":"bc388d6e-6d02-4811-c807-f7fe4036331f","trusted":true},"outputs":[],"source":["# Choose a image.\n","custom_image_path = \"/cat-vs-dog/test/dogs/dog.5.jpg\"\n","\n","import torchvision\n","# Load in custom image and convert the tensor values to float32\n","custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n","\n","# Divide the image pixel values by 255 to get them between [0, 1]\n","custom_image = custom_image / 255. \n","\n","# Print out image data\n","print(f\"Custom image tensor:\\n{custom_image}\\n\")\n","print(f\"Custom image shape: {custom_image.shape}\\n\")\n","print(f\"Custom image dtype: {custom_image.dtype}\")"]},{"cell_type":"markdown","metadata":{},"source":["Now let's create transform pipleine to resize image."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:18:52.008966Z","iopub.status.busy":"2023-01-25T20:18:52.008214Z","iopub.status.idle":"2023-01-25T20:18:52.029389Z","shell.execute_reply":"2023-01-25T20:18:52.027871Z","shell.execute_reply.started":"2023-01-25T20:18:52.008913Z"},"id":"63uu57_JowXg","outputId":"f6d63ccf-b0cf-402d-a97f-bd14f0766112","trusted":true},"outputs":[],"source":["custom_image_transform = transforms.Compose([\n","    transforms.Resize(IMAGE_SIZE),\n","])\n","\n","# Transform target image\n","custom_image_transformed = custom_image_transform(custom_image)\n","\n","# Print out original shape and new shape\n","print(f\"Original shape: {custom_image.shape}\")\n","print(f\"New shape: {custom_image_transformed.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["First, let's fit the image for the model with the function we created and then make a prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:19:13.746377Z","iopub.status.busy":"2023-01-25T20:19:13.745998Z","iopub.status.idle":"2023-01-25T20:19:13.758773Z","shell.execute_reply":"2023-01-25T20:19:13.757518Z","shell.execute_reply.started":"2023-01-25T20:19:13.746344Z"},"id":"62tSSQHro-_V","outputId":"f44c1e06-cb55-436b-e235-fec914c0d9b9","trusted":true},"outputs":[],"source":["model.eval()\n","with torch.inference_mode():\n","    # Add an extra dimension to image\n","    custom_image_transformed_with_batch_size = custom_image_transformed.unsqueeze(dim=0)\n","    \n","    # Print out different shapes\n","    print(f\"Custom image transformed shape: {custom_image_transformed.shape}\")\n","    print(f\"Unsqueezed custom image shape: {custom_image_transformed_with_batch_size.shape}\")\n","    \n","    # Make a prediction on image with an extra dimension\n","    custom_image_pred = model(custom_image_transformed.unsqueeze(dim=0).to(device))"]},{"cell_type":"markdown","metadata":{},"source":["Now let's take a look at our model's predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:19:17.445202Z","iopub.status.busy":"2023-01-25T20:19:17.444841Z","iopub.status.idle":"2023-01-25T20:19:17.456435Z","shell.execute_reply":"2023-01-25T20:19:17.455502Z","shell.execute_reply.started":"2023-01-25T20:19:17.44517Z"},"id":"V8ie7MCupO3H","outputId":"7f0d8adb-3566-47af-fa4f-b84e8777e5fa","trusted":true},"outputs":[],"source":["custom_image_pred"]},{"cell_type":"markdown","metadata":{},"source":["Nice! we've seen the prediction values of the model. Let's take a look at the prediction class. First, let me show you the prediction values."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:21:07.266822Z","iopub.status.busy":"2023-01-25T20:21:07.266421Z","iopub.status.idle":"2023-01-25T20:21:07.277135Z","shell.execute_reply":"2023-01-25T20:21:07.276022Z","shell.execute_reply.started":"2023-01-25T20:21:07.266787Z"},"id":"g7K5cDOqpYqM","outputId":"1e004d6c-7338-46b5-a44b-e13bd6da7d1f","trusted":true},"outputs":[],"source":["# Let's convert them from logits -> prediction probabilities -> prediction labels\n","# Print out prediction logits\n","print(f\"Prediction logits: {custom_image_pred}\")\n","\n","# Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n","custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)\n","print(f\"Prediction probabilities: {custom_image_pred_probs}\")\n","\n","# Convert prediction probabilities -> prediction labels\n","custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n","print(f\"Prediction label: {custom_image_pred_label}\")"]},{"cell_type":"markdown","metadata":{},"source":["It is time to find the predicted label."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:21:24.907931Z","iopub.status.busy":"2023-01-25T20:21:24.907569Z","iopub.status.idle":"2023-01-25T20:21:24.915563Z","shell.execute_reply":"2023-01-25T20:21:24.914504Z","shell.execute_reply.started":"2023-01-25T20:21:24.907901Z"},"id":"BOS4bcrVpfej","outputId":"a7f17784-9d01-43ce-bd55-c3333e22206d","trusted":true},"outputs":[],"source":["custom_image_pred_class = class_names[custom_image_pred_label.cpu()] # put pred label to CPU, otherwise will error\n","custom_image_pred_class"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize this image with matplotlib."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-25T20:21:38.518298Z","iopub.status.busy":"2023-01-25T20:21:38.517935Z","iopub.status.idle":"2023-01-25T20:21:38.764292Z","shell.execute_reply":"2023-01-25T20:21:38.763359Z","shell.execute_reply.started":"2023-01-25T20:21:38.518265Z"},"id":"XC8l1iqApxXX","outputId":"8bceeaf0-b2aa-42d1-cb6a-3fd01a40d702","trusted":true},"outputs":[],"source":["# Plot custom image\n","plt.imshow(custom_image.permute(1, 2, 0)) # need to permute image dimensions from CHW -> HWC otherwise matplotlib will error\n","plt.title(f\"Image shape: {custom_image.shape}\")\n","plt.axis(False);"]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion\n","\n","In this notebook, you learned how to build an image classification model from scratch with Pytorch. Tensorflow is generally preferred for deep learning projects. However, with Pytorch you can better control the deep-learning analysis steps. Pytorch has been preferred more recently, especially in the academic community. we also talked about data augmentation and highlighted the importance of this technique. I hope you like it. Let me know if you have any questions."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":23777,"sourceId":30378,"sourceType":"datasetVersion"}],"dockerImageVersionId":30357,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
